---
# Source: kafka/templates/provisioning/job.yaml
kind: Job
apiVersion: batch/v1
metadata:
  name: logging-kafka-provisioning
  namespace: "netwok-logging"
  labels:
    app.kubernetes.io/instance: logging
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kafka
    app.kubernetes.io/version: 3.8.0
    helm.sh/chart: kafka-30.0.4
    app.kubernetes.io/component: kafka-provisioning
  annotations:
    helm.sh/hook: post-install,post-upgrade
    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded
spec:
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: logging
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: kafka
        app.kubernetes.io/version: 3.8.0
        helm.sh/chart: kafka-30.0.4
        app.kubernetes.io/component: kafka-provisioning
    spec:
      serviceAccountName: logging-kafka-provisioning
      automountServiceAccountToken: false
      enableServiceLinks: true
      
      securityContext:
        fsGroup: 1001
        fsGroupChangePolicy: Always
        seccompProfile:
          type: RuntimeDefault
        supplementalGroups: []
        sysctls: []
      restartPolicy: OnFailure
      terminationGracePeriodSeconds: 0
      initContainers:
        - name: wait-for-available-kafka
          image: docker.io/bitnami/kafka:3.8.0-debian-12-r0
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seLinuxOptions: {}
          command:
            - /bin/bash
          args:
            - -ec
            - |
              wait-for-port \
                --host=logging-kafka \
                --state=inuse \
                --timeout=120 \
                9092;
              echo "Kafka is available";
          resources:
            limits:
              cpu: 375m
              ephemeral-storage: 2Gi
              memory: 384Mi
            requests:
              cpu: 250m
              ephemeral-storage: 50Mi
              memory: 256Mi
      containers:
        - name: kafka-provisioning
          image: docker.io/bitnami/kafka:3.8.0-debian-12-r0
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seLinuxOptions: {}
          command:
            - /bin/bash
          args:
            - -efc
            - |
              echo "Configuring environment"
              . /opt/bitnami/scripts/libkafka.sh
              export CLIENT_CONF="${CLIENT_CONF:-/tmp/client.properties}"
              if [ ! -f "$CLIENT_CONF" ]; then
                touch $CLIENT_CONF

                kafka_common_conf_set "$CLIENT_CONF" security.protocol "SASL_PLAINTEXT"
                kafka_common_conf_set "$CLIENT_CONF" sasl.mechanism PLAIN
                kafka_common_conf_set "$CLIENT_CONF" sasl.jaas.config "org.apache.kafka.common.security.plain.PlainLoginModule required username=\"$SASL_USERNAME\" password=\"$SASL_USER_PASSWORD\";"
              fi

              echo "Running pre-provisioning script if any given"
              
              

              kafka_provisioning_commands=(
                "/opt/bitnami/kafka/bin/kafka-topics.sh \
                    --create \
                    --if-not-exists \
                    --bootstrap-server ${KAFKA_SERVICE} \
                    --replication-factor 2 \
                    --partitions 2 \
                    --config flush.messages=1 \
                    --config max.message.bytes=64000 \
                    --config retention.bytes=209715200 \
                    --config retention.ms=86400000 \
                    --config segment.bytes=104857600 \
                    --command-config ${CLIENT_CONF} \
                    --topic sglog"
              )

              echo "Starting provisioning"
              for ((index=0; index < ${#kafka_provisioning_commands[@]}; index+=1))
              do
                for j in $(seq ${index} $((${index}+1-1)))
                do
                    ${kafka_provisioning_commands[j]} & # Async command
                done
                wait  # Wait the end of the jobs
              done

              echo "Running post-provisioning script if any given"
              
              

              echo "Provisioning succeeded"
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: KAFKA_SERVICE
              value: logging-kafka:9092
            - name: SASL_USERNAME
              value: "user1"
            - name: SASL_USER_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: logging-kafka-user-passwords
                  key: system-user-password
          resources:
            limits:
              cpu: 375m
              ephemeral-storage: 2Gi
              memory: 384Mi
            requests:
              cpu: 250m
              ephemeral-storage: 50Mi
              memory: 256Mi
          volumeMounts:
            - name: tmp
              mountPath: /tmp
      volumes:
        - name: tmp
          emptyDir: {}
